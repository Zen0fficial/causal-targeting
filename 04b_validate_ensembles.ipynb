{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 04b Validate Ensembles with Indicator B at q* = 0.9\n",
    "\n",
    "This notebook implements **Stage 2B** of the ESTIMATOR_RANKING_PLAN:\n",
    "\n",
    "1. For each (Q, k) configuration, compute indicator B at fixed q* = 0.9\n",
    "2. Compute B̄_0.9 (proportion of folds where top subgroup outperforms complement)\n",
    "3. Compute Δτ̄_0.9 (mean treatment effect difference)\n",
    "4. Identify optimal (Q*, k*) configuration\n",
    "\n",
    "**Fixed validation quantile:** q* = 0.9 (top 10% of predicted effects)\n",
    "\n",
    "**Selection criteria:**\n",
    "- Primary: B̄_0.9 = 1.0 (or ≥ 0.95 if relaxed)\n",
    "- Secondary: Largest Δτ̄_0.9 among passing configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "setup-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure output directories exist\n",
    "OUTPUT_PATH = Path(\"output/analysis\")\n",
    "INTERMEDIATE_PATH = Path(\"output/intermediate/grid_search\")\n",
    "for p in [OUTPUT_PATH, INTERMEDIATE_PATH]:\n",
    "    p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "from functools import lru_cache\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom methods\n",
    "from methods.causal_functions import get_subgroup_CATE, get_subgroup_t_statistic, get_subgroup_t_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: fausebal\n",
      "Fixed validation quantile: q* = 0.9 (top 9%)\n",
      "Direction: Positive effects preferred\n"
     ]
    }
   ],
   "source": [
    "# Analysis configuration\n",
    "OUTCOME_NAME = \"fausebal\"\n",
    "DIR_NEG = False  # We want POSITIVE treatment effects\n",
    "\n",
    "# Fixed validation quantile\n",
    "Q_STAR = 0.9  # Top 10% (q* = 0.9 means top 10% when dir_neg=False)\n",
    "\n",
    "# Grid search parameters (same as 04a)\n",
    "Q_SETS = {\n",
    "    \"Q1\": np.array([0.1]),\n",
    "    \"Q2\": np.array([0.1, 0.2]),\n",
    "    \"Q3\": np.array([0.1, 0.2, 0.3]),\n",
    "    \"Q4\": np.array([0.1, 0.2, 0.3, 0.4]),\n",
    "    \"Q5\": np.array([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "}\n",
    "\n",
    "K_VALUES = list(range(1, 11))  # k ∈ {1, 2, ..., 10}\n",
    "\n",
    "print(f\"Outcome: {OUTCOME_NAME}\")\n",
    "print(f\"Fixed validation quantile: q* = {Q_STAR} (top {int((1-Q_STAR)*100)}%)\")\n",
    "print(f\"Direction: {'Negative' if DIR_NEG else 'Positive'} effects preferred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 2. Load Data from 04a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fitted libraries\n",
      "Loaded ensemble table\n"
     ]
    }
   ],
   "source": [
    "# Load fitted libraries\n",
    "fitted_libraries = joblib.load(f\"output/analysis/{OUTCOME_NAME}/{OUTCOME_NAME}_fitted_libraries.pkl\")\n",
    "print(f\"Loaded fitted libraries\")\n",
    "\n",
    "# Load ensemble table from 04a\n",
    "ensemble_table = joblib.load(INTERMEDIATE_PATH / f\"{OUTCOME_NAME}_ensemble_table.pkl\")\n",
    "print(f\"Loaded ensemble table\")\n",
    "\n",
    "# Get perturbation names\n",
    "perturbations = [\"none\", \"cv_0\", \"cv_1\"]\n",
    "n_folds = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indicator-header",
   "metadata": {},
   "source": [
    "## 3. Compute Indicator B at q* = 0.9\n",
    "\n",
    "For each ensemble we average its members' CATE predictions within every (perturbation, fold), build the top-q* subgroup from that ensemble prediction, and evaluate on the validation samples only:\n",
    "- **B_0.9 = 1** if τ̂_top ≥ τ̂_complement (positive effects) or τ̂_top ≤ τ̂_complement (negative effects)\n",
    "- **Δτ_0.9 = τ̂_top − τ̂_complement**\n",
    "\n",
    "These per-fold metrics feed into the aggregation step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compute-indicator-B",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_subgroup_masks(tau_values, train_mask, val_mask, q_star, dir_neg):\n",
    "    \"\"\"Build boolean masks for the desired quantile subgroup based on ensemble predictions.\"\"\"\n",
    "    tau_train = tau_values[train_mask]\n",
    "    if tau_train.size == 0:\n",
    "        return None, None\n",
    "    if dir_neg:\n",
    "        q_bot, q_top = 0.0, max(0.0, 1.0 - q_star)\n",
    "    else:\n",
    "        q_bot, q_top = q_star, 1.0\n",
    "    quantile_top = np.quantile(tau_train, min(q_top, 1.0))\n",
    "    if q_bot <= 0:\n",
    "        base_indicator = tau_values <= quantile_top\n",
    "    else:\n",
    "        quantile_bot = np.quantile(tau_train, q_bot)\n",
    "        base_indicator = (tau_values > quantile_bot) & (tau_values <= quantile_top)\n",
    "    subgroup_mask = base_indicator & val_mask\n",
    "    complement_mask = val_mask & (~subgroup_mask)\n",
    "    return subgroup_mask, complement_mask\n",
    "\n",
    "\n",
    "def has_treated_and_control(t_vector, mask):\n",
    "    \"\"\"Ensure both treatment arms are represented within the mask.\"\"\"\n",
    "    subset = t_vector[mask]\n",
    "    if subset.size == 0:\n",
    "        return False\n",
    "    return np.any(subset == 1) and np.any(subset == 0)\n",
    "\n",
    "\n",
    "def canonical_key(ensemble):\n",
    "    \"\"\"Return a sorted tuple key for caching ensemble metrics.\"\"\"\n",
    "    return tuple(sorted(ensemble))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_ensemble_fold_metrics(ensemble_key):\n",
    "    \"\"\"Compute raw B values, delta values, and t-statistics for an ensemble across all folds.\"\"\"\n",
    "    if len(ensemble_key) == 0:\n",
    "        return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    B_values = []\n",
    "    delta_values = []\n",
    "    t_stat_values = []\n",
    "    for pert_name, library in fitted_libraries.items():\n",
    "        missing = [est for est in ensemble_key if est not in library]\n",
    "        if missing:\n",
    "            continue\n",
    "        ref_estimator = library[ensemble_key[0]]\n",
    "        y = ref_estimator.y\n",
    "        t = ref_estimator.t\n",
    "        n_splits = ref_estimator.n_splits\n",
    "        for fold in range(n_splits):\n",
    "            val_mask = ref_estimator.results[fold].val_indicator\n",
    "            train_mask = ref_estimator.results[fold].train_indicator\n",
    "            tau_stack = np.stack([library[est].results[fold].tau for est in ensemble_key])\n",
    "            ensemble_tau = np.mean(tau_stack, axis=0)\n",
    "            subgroup_mask, complement_mask = build_subgroup_masks(\n",
    "                ensemble_tau, train_mask, val_mask, Q_STAR, DIR_NEG\n",
    "            )\n",
    "            if subgroup_mask is None or complement_mask is None:\n",
    "                continue\n",
    "            if subgroup_mask.sum() == 0 or complement_mask.sum() == 0:\n",
    "                continue\n",
    "            if not has_treated_and_control(t, subgroup_mask):\n",
    "                continue\n",
    "            if not has_treated_and_control(t, complement_mask):\n",
    "                continue\n",
    "            tau_top = get_subgroup_CATE(y, t, subgroup_mask)\n",
    "            tau_complement = get_subgroup_CATE(y, t, complement_mask)\n",
    "            if not np.isfinite(tau_top) or not np.isfinite(tau_complement):\n",
    "                continue\n",
    "            if DIR_NEG:\n",
    "                B = 1 if tau_top <= tau_complement else 0\n",
    "            else:\n",
    "                B = 1 if tau_top >= tau_complement else 0\n",
    "            B_values.append(B)\n",
    "            delta_values.append(tau_top - tau_complement)\n",
    "            # Compute t-statistic for the subgroup (CATE_sg - ATE) / SE\n",
    "            t_stat_fold = get_subgroup_t_statistic(y, t, subgroup_mask, val_mask)\n",
    "            t_stat_values.append(t_stat_fold if np.isfinite(t_stat_fold) else np.nan)\n",
    "    return np.array(B_values), np.array(delta_values), np.array(t_stat_values)\n",
    "\n",
    "\n",
    "def summarize_ensemble_metrics(ensemble):\n",
    "    \"\"\"Aggregate B, delta, and t-statistic for a given ensemble list.\"\"\"\n",
    "    key = canonical_key(tuple(ensemble))\n",
    "    B_vals, delta_vals, t_stat_vals = compute_ensemble_fold_metrics(key)\n",
    "    finite_t = t_stat_vals[np.isfinite(t_stat_vals)]\n",
    "    return {\n",
    "        \"B_bar\": float(np.mean(B_vals)),\n",
    "        \"delta_bar\": float(np.mean(delta_vals)),\n",
    "        \"delta_std\": float(np.std(delta_vals, ddof=0)),\n",
    "        \"t_bar\": float(np.mean(finite_t)) if finite_t.size > 0 else np.nan,\n",
    "        \"n_folds_used\": int(delta_vals.size),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aggregate-B",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble metrics to output/intermediate/grid_search/fausebal_ensemble_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics for unique ensembles for reference\n",
    "unique_records = []\n",
    "seen_keys = set()\n",
    "\n",
    "for Q_name, config in ensemble_table.items():\n",
    "    for k, ensemble in config.items():\n",
    "        if not ensemble:\n",
    "            continue\n",
    "        key = canonical_key(tuple(ensemble))\n",
    "        if key in seen_keys:\n",
    "            continue\n",
    "        seen_keys.add(key)\n",
    "        metrics = summarize_ensemble_metrics(ensemble)\n",
    "        unique_records.append({\n",
    "            \"ensemble\": \", \".join(ensemble),\n",
    "            \"size\": len(ensemble),\n",
    "            \"B_bar_0.9\": metrics[\"B_bar\"],\n",
    "            \"delta_bar_0.9\": metrics[\"delta_bar\"],\n",
    "            \"delta_std_0.9\": metrics[\"delta_std\"],\n",
    "            \"t_bar_0.9\": metrics[\"t_bar\"],\n",
    "            \"n_folds_used\": metrics[\"n_folds_used\"],\n",
    "        })\n",
    "\n",
    "ensemble_metrics_df = pd.DataFrame(unique_records)\n",
    "if not ensemble_metrics_df.empty:\n",
    "    ensemble_metrics_df = ensemble_metrics_df.sort_values(\n",
    "        [\"B_bar_0.9\", \"delta_bar_0.9\"], ascending=[False, False]\n",
    "    )\n",
    "    csv_path = INTERMEDIATE_PATH / f\"{OUTCOME_NAME}_ensemble_metrics.csv\"\n",
    "    ensemble_metrics_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved ensemble metrics to {csv_path}\")\n",
    "    ensemble_metrics_df.head()\n",
    "else:\n",
    "    print(\"No non-empty ensembles available for metric computation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble-validation-header",
   "metadata": {},
   "source": [
    "## 4. Validate Each (Q, k) Configuration\n",
    "\n",
    "For each ensemble, compute aggregate B̄_0.9 and Δτ̄_0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "validate-ensembles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation results to output/intermediate/grid_search/fausebal_validation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Compute validation metrics for each (Q, k) configuration\n",
    "validation_results = []\n",
    "\n",
    "for Q_name in Q_SETS.keys():\n",
    "    for k in K_VALUES:\n",
    "        ensemble = ensemble_table[Q_name][k]\n",
    "\n",
    "        if not ensemble:\n",
    "            validation_results.append({\n",
    "                \"Q\": Q_name,\n",
    "                \"k\": k,\n",
    "                \"n_estimators\": 0,\n",
    "                \"estimators\": \"\",\n",
    "                \"B_bar_0.9\": np.nan,\n",
    "                \"delta_bar_0.9\": np.nan,\n",
    "                \"delta_std_0.9\": np.nan,\n",
    "                \"t_bar_0.9\": np.nan,\n",
    "                \"n_folds_used\": 0,\n",
    "                \"passes_strict\": False,\n",
    "                \"passes_relaxed\": False,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        metrics = summarize_ensemble_metrics(ensemble)\n",
    "        B_bar = metrics[\"B_bar\"]\n",
    "        delta_bar = metrics[\"delta_bar\"]\n",
    "        delta_std = metrics[\"delta_std\"]\n",
    "        t_bar = metrics[\"t_bar\"]\n",
    "        n_folds_used = metrics[\"n_folds_used\"]\n",
    "\n",
    "        passes_strict = np.isclose(B_bar, 1.0) if not np.isnan(B_bar) else False\n",
    "        passes_relaxed = (B_bar >= 0.95) if not np.isnan(B_bar) else False\n",
    "\n",
    "        validation_results.append({\n",
    "            \"Q\": Q_name,\n",
    "            \"k\": k,\n",
    "            \"n_estimators\": len(ensemble),\n",
    "            \"estimators\": \", \".join(ensemble),\n",
    "            \"B_bar_0.9\": B_bar,\n",
    "            \"delta_bar_0.9\": delta_bar,\n",
    "            \"delta_std_0.9\": delta_std,\n",
    "            \"t_bar_0.9\": t_bar,\n",
    "            \"n_folds_used\": n_folds_used,\n",
    "            \"passes_strict\": passes_strict,\n",
    "            \"passes_relaxed\": passes_relaxed,\n",
    "        })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_results)\n",
    "\n",
    "# Save validation results\n",
    "validation_df.to_csv(INTERMEDIATE_PATH / f\"{OUTCOME_NAME}_validation_results.csv\", index=False)\n",
    "print(f\"Saved validation results to {INTERMEDIATE_PATH / f'{OUTCOME_NAME}_validation_results.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "display-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results for (Q, k) Configurations:\n",
      "================================================================================\n",
      " Q  k  n_estimators  B_bar_0.9  delta_bar_0.9  delta_std_0.9  t_bar_0.9  n_folds_used  passes_strict  passes_relaxed\n",
      "Q3 10             5   0.916667       0.014296       0.024718   0.381860            12          False           False\n",
      "Q4 10             5   0.916667       0.014296       0.024718   0.381860            12          False           False\n",
      "Q4  9             4   0.833333       0.029442       0.037014   0.785744            12          False           False\n",
      "Q5  8             4   0.833333       0.029442       0.037014   0.785744            12          False           False\n",
      "Q5  9             5   0.833333       0.028368       0.026570   0.758069            12          False           False\n",
      "Q5 10             5   0.833333       0.028368       0.026570   0.758069            12          False           False\n",
      "Q3  7             2   0.750000       0.031610       0.044946   0.845787            12          False           False\n",
      "Q4  6             2   0.750000       0.031610       0.044946   0.845787            12          False           False\n",
      "Q4  7             2   0.750000       0.031610       0.044946   0.845787            12          False           False\n",
      "Q5  6             2   0.750000       0.031610       0.044946   0.845787            12          False           False\n",
      "Q5  7             2   0.750000       0.031610       0.044946   0.845787            12          False           False\n",
      "Q3  8             3   0.750000       0.027312       0.046840   0.735683            12          False           False\n",
      "Q3  9             3   0.750000       0.027312       0.046840   0.735683            12          False           False\n",
      "Q4  8             3   0.750000       0.027312       0.046840   0.735683            12          False           False\n",
      "Q2 10             4   0.750000       0.020161       0.025933   0.526616            12          False           False\n",
      "Q1  8             1   0.666667       0.021953       0.044679   0.524653            12          False           False\n",
      "Q1  9             1   0.666667       0.021953       0.044679   0.524653            12          False           False\n",
      "Q1 10             1   0.666667       0.021953       0.044679   0.524653            12          False           False\n",
      "Q2  7             3   0.666667       0.015632       0.032097   0.400452            12          False           False\n",
      "Q2  8             3   0.666667       0.015632       0.032097   0.400452            12          False           False\n",
      "Q2  9             3   0.666667       0.015632       0.032097   0.400452            12          False           False\n",
      "Q2  6             1   0.500000       0.010151       0.031741   0.265147            12          False           False\n",
      "Q3  6             1   0.416667       0.004500       0.041901   0.158163            12          False           False\n",
      "Q5  5             1   0.416667       0.004500       0.041901   0.158163            12          False           False\n"
     ]
    }
   ],
   "source": [
    "# Display validation results\n",
    "print(\"Validation Results for (Q, k) Configurations:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "valid_df = validation_df[validation_df[\"n_estimators\"] > 0].copy()\n",
    "valid_df = valid_df.sort_values([\"B_bar_0.9\", \"delta_bar_0.9\"], ascending=[False, False])\n",
    "columns = [\n",
    "    \"Q\",\n",
    "    \"k\",\n",
    "    \"n_estimators\",\n",
    "    \"B_bar_0.9\",\n",
    "    \"delta_bar_0.9\",\n",
    "    \"delta_std_0.9\",\n",
    "    \"t_bar_0.9\",\n",
    "    \"n_folds_used\",\n",
    "    \"passes_strict\",\n",
    "    \"passes_relaxed\",\n",
    "]\n",
    "\n",
    "if valid_df.empty:\n",
    "    print(\"No non-empty ensembles available.\")\n",
    "else:\n",
    "    print(valid_df[columns].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selection-header",
   "metadata": {},
   "source": [
    "## 5. Select Optimal (Q*, k*) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "select-optimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configurations pass STRICT criterion. Trying RELAXED criterion (B̄_0.9 >= 0.95)...\n",
      "\n",
      "No configurations pass RELAXED criterion either.\n",
      "Selecting configuration with highest B̄_0.9...\n"
     ]
    }
   ],
   "source": [
    "# Selection procedure:\n",
    "# 1. Primary: B̄_0.9 = 1.0 (strict criterion)\n",
    "# 2. Secondary: Largest Δτ̄_0.9 among passing configurations\n",
    "\n",
    "optimal = None\n",
    "criterion_used = \"none\"\n",
    "\n",
    "strict_passing = validation_df[validation_df[\"passes_strict\"] == True]\n",
    "\n",
    "if not strict_passing.empty:\n",
    "    print(\"Configurations passing STRICT criterion (B̄_0.9 = 1.0):\")\n",
    "    print(\n",
    "        strict_passing[\n",
    "            [\"Q\", \"k\", \"n_estimators\", \"B_bar_0.9\", \"delta_bar_0.9\", \"estimators\"]\n",
    "        ].to_string(index=False)\n",
    "    )\n",
    "\n",
    "    # Select the one with largest delta\n",
    "    optimal = strict_passing.loc[strict_passing[\"delta_bar_0.9\"].idxmax()]\n",
    "    criterion_used = \"strict\"\n",
    "else:\n",
    "    print(\"No configurations pass STRICT criterion. Trying RELAXED criterion (B̄_0.9 >= 0.95)...\")\n",
    "    relaxed_passing = validation_df[validation_df[\"passes_relaxed\"] == True]\n",
    "\n",
    "    if not relaxed_passing.empty:\n",
    "        print(\"\\nConfigurations passing RELAXED criterion:\")\n",
    "        print(\n",
    "            relaxed_passing[\n",
    "                [\"Q\", \"k\", \"n_estimators\", \"B_bar_0.9\", \"delta_bar_0.9\", \"estimators\"]\n",
    "            ].to_string(index=False)\n",
    "        )\n",
    "\n",
    "        # Select the one with largest delta\n",
    "        optimal = relaxed_passing.loc[relaxed_passing[\"delta_bar_0.9\"].idxmax()]\n",
    "        criterion_used = \"relaxed\"\n",
    "    else:\n",
    "        print(\"\\nNo configurations pass RELAXED criterion either.\")\n",
    "        print(\"Selecting configuration with highest B̄_0.9...\")\n",
    "\n",
    "        valid_configs = validation_df[validation_df[\"n_estimators\"] > 0]\n",
    "        if valid_configs.empty:\n",
    "            print(\"No valid configurations with non-empty ensembles were found.\")\n",
    "            optimal = None\n",
    "            criterion_used = \"none\"\n",
    "        else:\n",
    "            optimal = valid_configs.loc[valid_configs[\"B_bar_0.9\"].idxmax()]\n",
    "            criterion_used = \"best_available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "display-optimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMAL CONFIGURATION (Q*, k*)\n",
      "================================================================================\n",
      "\n",
      "Criterion used: best_available\n",
      "\n",
      "Q* = Q3\n",
      "k* = 10\n",
      "Number of estimators: 5\n",
      "Estimators: x_xgb, causal_tree_1, x_rf, t_rf, x_logistic\n",
      "\n",
      "Validation metrics at q* = 0.9:\n",
      "  B̄_0.9 = 0.9167\n",
      "  Δτ̄_0.9 = 0.0143\n",
      "  t̄_0.9 = 0.3819\n"
     ]
    }
   ],
   "source": [
    "# Display optimal configuration\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMAL CONFIGURATION (Q*, k*)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if optimal is None:\n",
    "    print(\"\\nNo optimal configuration could be selected.\")\n",
    "else:\n",
    "    print(f\"\\nCriterion used: {criterion_used}\")\n",
    "    print(f\"\\nQ* = {optimal['Q']}\")\n",
    "    print(f\"k* = {optimal['k']}\")\n",
    "    print(f\"Number of estimators: {optimal['n_estimators']}\")\n",
    "    print(f\"Estimators: {optimal['estimators']}\")\n",
    "    print(f\"\\nValidation metrics at q* = {Q_STAR}:\")\n",
    "    print(f\"  B̄_0.9 = {optimal['B_bar_0.9']:.4f}\")\n",
    "    print(f\"  Δτ̄_0.9 = {optimal['delta_bar_0.9']:.4f}\")\n",
    "    print(f\"  t̄_0.9 = {optimal['t_bar_0.9']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "save-optimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved optimal configuration to output/intermediate/grid_search/fausebal_optimal_config.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save optimal configuration\n",
    "optimal_config = None\n",
    "if optimal is None:\n",
    "    print(\"\\nSkipping save because no optimal configuration was selected.\")\n",
    "else:\n",
    "    optimal_config = {\n",
    "        \"Q_star\": optimal[\"Q\"],\n",
    "        \"k_star\": optimal[\"k\"],\n",
    "        \"q_star\": Q_STAR,\n",
    "        \"estimators\": optimal[\"estimators\"].split(\", \") if optimal[\"estimators\"] else [],\n",
    "        \"B_bar_0.9\": optimal[\"B_bar_0.9\"],\n",
    "        \"delta_bar_0.9\": optimal[\"delta_bar_0.9\"],\n",
    "        \"t_bar_0.9\": optimal[\"t_bar_0.9\"],\n",
    "        \"criterion_used\": criterion_used,\n",
    "    }\n",
    "\n",
    "    joblib.dump(optimal_config, INTERMEDIATE_PATH / f\"{OUTCOME_NAME}_optimal_config.pkl\")\n",
    "    print(f\"\\nSaved optimal configuration to {INTERMEDIATE_PATH / f'{OUTCOME_NAME}_optimal_config.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "**Outputs saved:**\n",
    "1. `{OUTCOME_NAME}_estimator_B_metrics.csv` - B̄_0.9 and Δτ̄_0.9 for each estimator\n",
    "2. `{OUTCOME_NAME}_validation_results.csv` - Validation metrics for each (Q, k) configuration\n",
    "3. `{OUTCOME_NAME}_optimal_config.pkl` - Optimal (Q*, k*) configuration\n",
    "\n",
    "**Next steps:**\n",
    "- Notebook 05b: Fit final ensemble on full training/validation sample\n",
    "- Validate on holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "final-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Fixed validation quantile: q* = 0.9\n",
      "\n",
      "Optimal configuration:\n",
      "  Q* = Q3\n",
      "  k* = 10\n",
      "  Estimators: ['x_xgb', 'causal_tree_1', 'x_rf', 't_rf', 'x_logistic']\n",
      "\n",
      "Validation metrics:\n",
      "  B̄_0.9 = 0.9167\n",
      "  Δτ̄_0.9 = 0.0143\n",
      "  t̄_0.9 = 0.3819\n",
      "\n",
      "Criterion used: best_available\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFixed validation quantile: q* = {Q_STAR}\")\n",
    "\n",
    "if optimal_config is None:\n",
    "    print(\"\\nNo optimal configuration was saved.\")\n",
    "else:\n",
    "    print(\"\\nOptimal configuration:\")\n",
    "    print(f\"  Q* = {optimal_config['Q_star']}\")\n",
    "    print(f\"  k* = {optimal_config['k_star']}\")\n",
    "    print(f\"  Estimators: {optimal_config['estimators']}\")\n",
    "    print(\"\\nValidation metrics:\")\n",
    "    print(f\"  B̄_0.9 = {optimal_config['B_bar_0.9']:.4f}\")\n",
    "    print(f\"  Δτ̄_0.9 = {optimal_config['delta_bar_0.9']:.4f}\")\n",
    "    print(f\"  t̄_0.9 = {optimal_config['t_bar_0.9']:.4f}\")\n",
    "    print(f\"\\nCriterion used: {optimal_config['criterion_used']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
