{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Orthogonality Data Preparation\n",
        "\n",
        "**Equivalent to:** `data7_orthogonality.do`\n",
        "\n",
        "**Purpose:** Creating orthogonality table data from the main customer dataset\n",
        "\n",
        "This notebook recreates the data processing pipeline that:\n",
        "1. Loads the main customer dataset (`all.dta`)\n",
        "2. Filters to pre-campaign period (September 2011 - August 2012) \n",
        "3. Cleans and processes variables for balance checks\n",
        "4. Creates customer-level aggregated variables\n",
        "5. Saves as `orthogonality.parquet` for analysis\n",
        "\n",
        "**Original Stata Code Logic:**\n",
        "- Keeps only pre-campaign period data\n",
        "- Cleans numeric variables (removes \"(null)\", converts to numeric)\n",
        "- Creates customer-level means for key variables\n",
        "- Collapses to one row per customer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orthogonality Data Preparation\n",
            "========================================\n",
            "Equivalent to: data7_orthogonality.do\n",
            "Input: /Users/zenofficial/Documents/statistics/pcs/turkey_python_analysis/data/bankdata/clean/all.dta\n",
            "Output: /Users/zenofficial/Documents/statistics/pcs/turkey_python_analysis/data/analysis/orthogonality.parquet\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project paths\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.append(str(project_root / 'config'))\n",
        "\n",
        "import config\n",
        "import pyreadstat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Orthogonality Data Preparation\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Equivalent to: data7_orthogonality.do\")\n",
        "print(f\"Input: {config.DATASETS['all']}\")\n",
        "print(f\"Output: {config.ANALYSIS_DATA_DIR / 'orthogonality.parquet'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading main customer dataset...\n",
            "✓ Loaded from parquet: (1836354, 42)\n",
            "Date range in data: 619.0 to 636.0\n",
            "Unique customers: 108000\n",
            "Sample columns: ['id', 'date', 'before', 'TreatVars', 'treatment', 'desc', 'StratVars', 'cinsiyet', 'kametili', 'istanbul']\n"
          ]
        }
      ],
      "source": [
        "# Load main dataset directly from Stata file\n",
        "print(\"Loading main customer dataset...\")\n",
        "\n",
        "df, meta = pyreadstat.read_dta(str(config.DATASETS['all']))\n",
        "print(f\"✓ Loaded from Stata file: {df.shape}\")\n",
        "\n",
        "print(f\"Date range in data: {df['date'].min()} to {df['date'].max()}\")\n",
        "print(f\"Unique customers: {df['id'].nunique()}\")\n",
        "print(f\"Sample columns: {list(df.columns[:10])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaning numeric variables...\n",
            "✓ Numeric variables cleaned\n",
            "\n",
            "Creating customer-level aggregated variables...\n",
            "✓ Created transactions from transnum\n",
            "✓ Created assets from a_total\n",
            "✓ Created deposits from a_deposit\n",
            "✓ Created paymentmean from payment\n",
            "✓ Created debt from debt_tot\n",
            "✓ Created pastuse variable\n",
            "✓ Created autobillpay variable\n",
            "Data shape after aggregation: (1296000, 49)\n"
          ]
        }
      ],
      "source": [
        "# Clean numeric variables first (equivalent to Stata foreach loop)\n",
        "print(\"\\nCleaning numeric variables...\")\n",
        "\n",
        "def clean_numeric_variables(df, variables):\n",
        "    \"\"\"Clean numeric variables (replaces \"(null)\" with NaN, converts to numeric)\"\"\"\n",
        "    df_clean = df.copy()\n",
        "    for var in variables:\n",
        "        if var in df_clean.columns:\n",
        "            df_clean[var] = df_clean[var].replace(\"(null)\", np.nan)\n",
        "            df_clean[var] = pd.to_numeric(df_clean[var], errors='coerce')\n",
        "            df_clean[var] = df_clean[var].fillna(0)\n",
        "    return df_clean\n",
        "\n",
        "numeric_vars = ['debt_tot', 'debt_term', 'transnum', 'instrucnum', 'cardsnum']\n",
        "df_clean = clean_numeric_variables(df_filtered, numeric_vars)\n",
        "\n",
        "# Handle other variables\n",
        "if 'creditcard' in df_clean.columns:\n",
        "    df_clean['creditcard'] = df_clean['creditcard'].fillna(0)\n",
        "if 'credit' in df_clean.columns:    \n",
        "    df_clean['credit'] = df_clean['credit'].fillna(0)\n",
        "if 'faamount' in df_clean.columns:\n",
        "    df_clean['faamount'] = df_clean['faamount'].fillna(0)\n",
        "\n",
        "print(\"✓ Numeric variables cleaned\")\n",
        "\n",
        "# Create customer-level aggregated variables (equivalent to Stata egen commands)\n",
        "print(\"\\nCreating customer-level aggregated variables...\")\n",
        "\n",
        "# Calculate customer-level means for key variables\n",
        "aggregation_vars = {\n",
        "    'transactions': 'transnum',\n",
        "    'assets': 'a_total', \n",
        "    'deposits': 'a_deposit',\n",
        "    'paymentmean': 'payment',\n",
        "    'debt': 'debt_tot'\n",
        "}\n",
        "\n",
        "df_agg = df_clean.copy()\n",
        "\n",
        "for new_var, source_var in aggregation_vars.items():\n",
        "    if source_var in df_agg.columns:\n",
        "        df_agg[new_var] = df_agg.groupby('id')[source_var].transform('mean')\n",
        "        print(f\"✓ Created {new_var} from {source_var}\")\n",
        "\n",
        "# Handle pastuse variable (equivalent to Stata pastuse creation)\n",
        "if 'faamount' in df_agg.columns:\n",
        "    df_agg['pastuse'] = df_agg.groupby('id')['faamount'].transform('mean')\n",
        "    df_agg['pastuse'] = (df_agg['pastuse'] != 0).astype(int)\n",
        "    print(\"✓ Created pastuse variable\")\n",
        "\n",
        "# Handle autobillpay variable \n",
        "if 'var3' in df_agg.columns:\n",
        "    df_agg['autobillpay'] = df_agg['var3'].fillna(0)\n",
        "    df_agg['autobillpay'] = df_agg.groupby('id')['autobillpay'].transform('mean')\n",
        "    df_agg['autobillpay'] = (df_agg['autobillpay'] != 0).astype(int)\n",
        "    print(\"✓ Created autobillpay variable\")\n",
        "\n",
        "print(f\"Data shape after aggregation: {df_agg.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collapsing to customer level...\n",
            "✓ Collapsed to 108,000 customers\n",
            "Final dataset shape: (108000, 17)\n",
            "Variables: ['id', 'treatment', 'phase1treat', 'cinsiyet', 'city', 'medenihal', 'falimit', 'transactions', 'assets', 'deposits', 'paymentmean', 'debt', 'pastuse', 'autobillpay', 'creditcard', 'credit', 'faamount']\n"
          ]
        }
      ],
      "source": [
        "# Collapse to one row per customer (equivalent to Stata collapse command)\n",
        "print(\"\\nCollapsing to customer level...\")\n",
        "\n",
        "# Define variables to keep and their aggregation methods\n",
        "keep_vars = ['id', 'treatment', 'phase1treat', 'cinsiyet', 'city', 'medenihal', \n",
        "             'falimit', 'transactions', 'assets', 'deposits', 'paymentmean', \n",
        "             'debt', 'pastuse', 'autobillpay', 'acctbalance']\n",
        "\n",
        "# Variables that use first non-missing value (firstnm in Stata)\n",
        "first_vars = ['treatment', 'phase1treat', 'cinsiyet', 'city', 'medenihal', \n",
        "              'falimit', 'transactions', 'assets', 'deposits', 'paymentmean', \n",
        "              'debt', 'pastuse', 'autobillpay']\n",
        "\n",
        "# Variables that use last non-missing value (lastnm in Stata)  \n",
        "last_vars = ['creditcard', 'credit']\n",
        "\n",
        "# Variables that use sum\n",
        "sum_vars = ['faamount']\n",
        "\n",
        "# Build aggregation dictionary\n",
        "agg_dict = {}\n",
        "for var in first_vars:\n",
        "    if var in df_agg.columns:\n",
        "        agg_dict[var] = 'first'\n",
        "\n",
        "for var in last_vars:\n",
        "    if var in df_agg.columns:\n",
        "        agg_dict[var] = 'last'\n",
        "        \n",
        "for var in sum_vars:\n",
        "    if var in df_agg.columns:\n",
        "        agg_dict[var] = 'sum'\n",
        "\n",
        "# Perform the collapse\n",
        "df_collapsed = df_agg.groupby('id').agg(agg_dict).reset_index()\n",
        "\n",
        "print(f\"✓ Collapsed to {len(df_collapsed):,} customers\")\n",
        "print(f\"Final dataset shape: {df_collapsed.shape}\")\n",
        "print(f\"Variables: {list(df_collapsed.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finalizing dataset...\n",
            "Summary of key variables:\n",
            "        treatment  transactions      assets    deposits        debt  \\\n",
            "count  108000.000    108000.000  107773.000  107773.000  108000.000   \n",
            "mean       18.487         1.636     638.896     377.300     283.393   \n",
            "std        10.390         4.213    2002.738    1032.487     715.635   \n",
            "min         1.000         0.000       0.000       0.000   -1733.083   \n",
            "25%         9.000         0.000      42.911      36.912       0.000   \n",
            "50%        18.000         0.000     147.350     118.202       0.000   \n",
            "75%        27.000         1.083     531.393     321.458     222.250   \n",
            "max        36.000        88.583  120975.639   54395.918   15057.083   \n",
            "\n",
            "          pastuse  \n",
            "count  108000.000  \n",
            "mean        0.304  \n",
            "std         0.460  \n",
            "min         0.000  \n",
            "25%         0.000  \n",
            "50%         0.000  \n",
            "75%         1.000  \n",
            "max         1.000  \n",
            "\n",
            "Treatment assignment counts:\n",
            "treatment\n",
            "9.0     3017\n",
            "3.0     3014\n",
            "2.0     3013\n",
            "12.0    3011\n",
            "15.0    3010\n",
            "6.0     3009\n",
            "27.0    3008\n",
            "34.0    3008\n",
            "33.0    3007\n",
            "1.0     3006\n",
            "26.0    3006\n",
            "17.0    3006\n",
            "18.0    3004\n",
            "7.0     3003\n",
            "28.0    3003\n",
            "32.0    3002\n",
            "19.0    3002\n",
            "5.0     3001\n",
            "21.0    3001\n",
            "8.0     3001\n",
            "4.0     3000\n",
            "13.0    2999\n",
            "24.0    2999\n",
            "11.0    2997\n",
            "22.0    2996\n",
            "20.0    2993\n",
            "35.0    2992\n",
            "14.0    2992\n",
            "23.0    2992\n",
            "10.0    2992\n",
            "25.0    2990\n",
            "29.0    2990\n",
            "36.0    2988\n",
            "16.0    2984\n",
            "30.0    2984\n",
            "31.0    2980\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✓ Saved orthogonality dataset to: /Users/zenofficial/Documents/statistics/pcs/turkey_python_analysis/data/analysis/orthogonality.parquet\n",
            "✓ Dataset ready for Table 1 analysis\n",
            "✓ Also saved as CSV: /Users/zenofficial/Documents/statistics/pcs/turkey_python_analysis/data/analysis/orthogonality.csv\n"
          ]
        }
      ],
      "source": [
        "# Add variable labels and save final dataset\n",
        "print(\"\\nFinalizing dataset...\")\n",
        "\n",
        "# Add variable labels (equivalent to Stata label var commands)\n",
        "var_labels = {\n",
        "    'treatment': 'Treatment',\n",
        "    'phase1treat': 'Treatment in First Phase Randomization',\n",
        "    'cinsiyet': 'Gender',\n",
        "    'city': 'City',\n",
        "    'medenihal': 'Marital Status',\n",
        "    'falimit': 'Overdraft Limit',\n",
        "    'transactions': 'Average Monthly Transactions',\n",
        "    'assets': 'Average Monthly Assets',\n",
        "    'deposits': 'Average Monthly Deposits', \n",
        "    'debt': 'Average Monthly Debt',\n",
        "    'pastuse': 'Past Overdraft Use (Binary)',\n",
        "    'autobillpay': 'Auto Bill Pay (Binary)'\n",
        "}\n",
        "\n",
        "# Show summary statistics\n",
        "print(\"Summary of key variables:\")\n",
        "summary_vars = ['treatment', 'transactions', 'assets', 'deposits', 'debt', 'pastuse']\n",
        "existing_summary_vars = [var for var in summary_vars if var in df_collapsed.columns]\n",
        "\n",
        "if existing_summary_vars:\n",
        "    summary_stats = df_collapsed[existing_summary_vars].describe()\n",
        "    print(summary_stats.round(3))\n",
        "\n",
        "# Check treatment balance\n",
        "if 'treatment' in df_collapsed.columns:\n",
        "    treatment_counts = df_collapsed['treatment'].value_counts()\n",
        "    print(f\"\\nTreatment assignment counts:\")\n",
        "    print(treatment_counts)\n",
        "\n",
        "# Save the final dataset\n",
        "output_path = config.ANALYSIS_DATA_DIR / 'orthogonality.parquet'\n",
        "df_collapsed.to_parquet(output_path, index=False)\n",
        "print(f\"\\n✓ Saved orthogonality dataset to: {output_path}\")\n",
        "print(f\"✓ Dataset ready for Table 1 analysis\")\n",
        "\n",
        "# Also save as CSV for easy viewing\n",
        "csv_path = config.ANALYSIS_DATA_DIR / 'orthogonality.csv'\n",
        "df_collapsed.to_csv(csv_path, index=False)\n",
        "print(f\"✓ Also saved as CSV: {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "debt_tot: min=-10271.0, max=42099.0, null_count=0\n",
            "\n",
            "✓ Data cleaning and aggregation completed successfully\n"
          ]
        }
      ],
      "source": [
        "# Show summary of key variables after cleaning\n",
        "if 'debt_tot' in df_clean.columns:\n",
        "    print(f\"debt_tot: min={df_clean['debt_tot'].min()}, max={df_clean['debt_tot'].max()}, null_count={df_clean['debt_tot'].isnull().sum()}\")\n",
        "\n",
        "print(\"\\n✓ Data cleaning and aggregation completed successfully\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
